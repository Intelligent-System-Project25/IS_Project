{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef8a598-e077-4e6b-a06d-1b9f99932765",
   "metadata": {},
   "source": [
    "Loading the dataset csv's into data frames and printing the first 10 values in the data set for each data frame to ensure that the data is being read and stored correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8292e8cb-ab63-426b-b2f1-71bfdae3746a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From Dataset 1: CO2 emission by countries\n",
      "       Country Code Calling Code  Year  CO2 emission (Tons)  Population(2022)  \\\n",
      "0  Afghanistan   AF           93  1750                  0.0        41128771.0   \n",
      "1  Afghanistan   AF           93  1751                  0.0        41128771.0   \n",
      "2  Afghanistan   AF           93  1752                  0.0        41128771.0   \n",
      "3  Afghanistan   AF           93  1753                  0.0        41128771.0   \n",
      "4  Afghanistan   AF           93  1754                  0.0        41128771.0   \n",
      "5  Afghanistan   AF           93  1755                  0.0        41128771.0   \n",
      "6  Afghanistan   AF           93  1756                  0.0        41128771.0   \n",
      "7  Afghanistan   AF           93  1757                  0.0        41128771.0   \n",
      "8  Afghanistan   AF           93  1758                  0.0        41128771.0   \n",
      "9  Afghanistan   AF           93  1759                  0.0        41128771.0   \n",
      "\n",
      "       Area % of World Density(km2)  \n",
      "0  652230.0      0.40%       63/km²  \n",
      "1  652230.0      0.40%       63/km²  \n",
      "2  652230.0      0.40%       63/km²  \n",
      "3  652230.0      0.40%       63/km²  \n",
      "4  652230.0      0.40%       63/km²  \n",
      "5  652230.0      0.40%       63/km²  \n",
      "6  652230.0      0.40%       63/km²  \n",
      "7  652230.0      0.40%       63/km²  \n",
      "8  652230.0      0.40%       63/km²  \n",
      "9  652230.0      0.40%       63/km²  \n",
      "\n",
      "\n",
      "From Dataset 2: Historical Tropical Storm\n",
      "     FID  YEAR  MONTH  DAY AD_TIME  BTID      NAME   LAT  LONG  WIND_KTS  \\\n",
      "0  18832  1851      7    5   1200Z     2  NOTNAMED  22.2 -97.6        80   \n",
      "1  22626  1851      8   21   0600Z     4  NOTNAMED  23.2 -82.5        60   \n",
      "2  22632  1851      8   21   1200Z     4  NOTNAMED  23.9 -83.6        70   \n",
      "3  23755  1851      8   20   1200Z     4  NOTNAMED  21.2 -79.0        70   \n",
      "4  23757  1851      8   20   1800Z     4  NOTNAMED  21.9 -80.4        70   \n",
      "5  23762  1851      8   21   0000Z     4  NOTNAMED  22.6 -81.4        60   \n",
      "6  24891  1851      8   20   0000Z     4  NOTNAMED  19.9 -75.9        70   \n",
      "7  24893  1851      8   20   0600Z     4  NOTNAMED  20.5 -77.6        70   \n",
      "8  25502  1851      8   19   1200Z     4  NOTNAMED  18.9 -72.6        60   \n",
      "9  25802  1851      8   19   1800Z     4  NOTNAMED  19.4 -74.3        60   \n",
      "\n",
      "   PRESSURE CAT           BASIN  Shape_Leng  \n",
      "0         0  H1  North Atlantic    0.141421  \n",
      "1         0  TS  North Atlantic    1.303840  \n",
      "2         0  H1  North Atlantic    0.860233  \n",
      "3         0  H1  North Atlantic    1.565248  \n",
      "4         0  H1  North Atlantic    1.220656  \n",
      "5         0  TS  North Atlantic    1.252996  \n",
      "6         0  H1  North Atlantic    1.802776  \n",
      "7         0  H1  North Atlantic    1.565248  \n",
      "8         0  TS  North Atlantic    1.772005  \n",
      "9         0  TS  North Atlantic    1.676305  \n",
      "\n",
      "\n",
      "From Dataset 3: global_temps\n",
      "   Year   Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov  \\\n",
      "0  1880 -0.19 -0.25 -0.09 -0.17 -0.10 -0.21 -0.18 -0.11 -0.15 -0.24 -0.22   \n",
      "1  1881 -0.20 -0.15  0.03  0.05  0.05 -0.19  0.00 -0.04 -0.16 -0.22 -0.19   \n",
      "2  1882  0.16  0.13  0.04 -0.16 -0.14 -0.22 -0.17 -0.08 -0.15 -0.24 -0.17   \n",
      "3  1883 -0.30 -0.37 -0.13 -0.19 -0.18 -0.08 -0.08 -0.14 -0.23 -0.12 -0.24   \n",
      "4  1884 -0.13 -0.09 -0.37 -0.40 -0.34 -0.35 -0.31 -0.28 -0.28 -0.25 -0.34   \n",
      "5  1885 -0.59 -0.34 -0.27 -0.42 -0.45 -0.44 -0.34 -0.32 -0.29 -0.24 -0.24   \n",
      "6  1886 -0.44 -0.51 -0.43 -0.28 -0.24 -0.35 -0.18 -0.31 -0.24 -0.28 -0.28   \n",
      "7  1887 -0.72 -0.57 -0.36 -0.35 -0.31 -0.25 -0.26 -0.36 -0.26 -0.36 -0.27   \n",
      "8  1888 -0.34 -0.36 -0.41 -0.20 -0.22 -0.17 -0.11 -0.16 -0.12  0.01  0.03   \n",
      "9  1889 -0.09  0.16  0.06  0.10 -0.01 -0.10 -0.08 -0.20 -0.24 -0.25 -0.33   \n",
      "\n",
      "    Dec   J-D   D-N   DJF   MAM   JJA   SON  \n",
      "0 -0.18 -0.17   NaN   NaN -0.12 -0.17 -0.20  \n",
      "1 -0.08 -0.09 -0.10 -0.18  0.04 -0.08 -0.19  \n",
      "2 -0.36 -0.11 -0.09  0.07 -0.09 -0.16 -0.19  \n",
      "3 -0.11 -0.18 -0.20 -0.34 -0.17 -0.10 -0.20  \n",
      "4 -0.31 -0.29 -0.27 -0.11 -0.37 -0.32 -0.29  \n",
      "5 -0.11 -0.34 -0.35 -0.41 -0.38 -0.36 -0.25  \n",
      "6 -0.26 -0.32 -0.30 -0.35 -0.32 -0.28 -0.27  \n",
      "7 -0.33 -0.37 -0.36 -0.52 -0.34 -0.29 -0.29  \n",
      "8 -0.04 -0.17 -0.20 -0.34 -0.28 -0.14 -0.03  \n",
      "9 -0.29 -0.11 -0.09  0.01  0.05 -0.13 -0.28  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_1 = pd.read_csv(\"CO2 emission by countries.csv\")\n",
    "dataset_2 = pd.read_csv(\"Historical Tropical Storm.csv\")\n",
    "dataset_3 = pd.read_csv(\"global_temps.csv\")\n",
    "\n",
    "print(\"From Dataset 1: CO2 emission by countries\")\n",
    "print(dataset_1.head(10))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"From Dataset 2: Historical Tropical Storm\")\n",
    "print(dataset_2.head(10))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"From Dataset 3: global_temps\")\n",
    "print(dataset_3.head(10))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0d0603",
   "metadata": {},
   "source": [
    "The \"CO2 emission by countries\" dataset currently has these attributes: Country\", \"Code\", \"Calling Code\", \"Year\", \"CO2 emission (Tons)\", \"Population(2022)\", \"Area\", \"% of World\" and \"Density(km2)\" but from this dataset we only require \"Year\" and \"CO2 emission (Tons)\" so the others will be removed to reduce the size of the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3959baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CO2 emission by countries dataset, has been updated\n"
     ]
    }
   ],
   "source": [
    "#Removing unnecessary columns from the datasets \"CO2 emission by countries\"\n",
    "dataset_1.columns = dataset_1.columns.str.strip()\n",
    "dropping = [\"Country\", \"Code\", \"Calling Code\", \"Population(2022)\", \"Area\", \"% of World\", \"Density(km2)\"]\n",
    "dataset_1.drop(columns=dropping, inplace= True, errors= \"ignore\")\n",
    "\n",
    "#updating the csv\n",
    "dataset_1.to_csv(\"CO2 emission by countries.csv\", index= False)\n",
    "print(\"CO2 emission by countries dataset, has been updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910a272e",
   "metadata": {},
   "source": [
    "The \"Historical Tropical Storm\" dataset currently has these attributes: \"FID\", \"YEAR\", \"MONTH\", \"DAY\", \"AD_TIME\", \"BTID\", \"NAME\", \"LAT\", \"LONG\", \"WIND_KTS\", \"PRESSURE\", \"CAT\", \"BASIN\" and \"Shape_Leng\" but from this dataset we only require \"YEAR\", \"MONTH\", \"DAY\", \"LAT\", \"LONG\", \"WIND_KTS\", \"PRESSURE\", \"CAT\" and \"Shape_Leng\" so the others will be removed to reduce the size of the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045d8cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical Tropical Storm dataset, has been updated\n"
     ]
    }
   ],
   "source": [
    "#Removing unnecessary columns from the dataset \"Historical Tropical Storm\"\n",
    "dataset_2.columns = dataset_2.columns.str.strip()\n",
    "dropping_2 = [\"FID\", \"AD_TIME\", \"BTID\", \"NAME\", \"BASIN\"]\n",
    "dataset_2.drop(columns=dropping_2, inplace= True, errors= \"ignore\")\n",
    "\n",
    "#updating the csv\n",
    "dataset_2.to_csv(\"Historical Tropical Storm.csv\", index= False)\n",
    "print(\"Historical Tropical Storm dataset, has been updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4582ef54",
   "metadata": {},
   "source": [
    "The \"global_temps\" dataset currently has these attributes: \"Year\", \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\", \"J-D\", \"D-N\", \"DJF\", \"MAM\", \"JJA\" and \"SON\" but from this dataset we only require \"Year\", \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\"and \"Dec\" so the others will be removed to reduce the size of the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5949d2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_temps dataset, has been updated\n"
     ]
    }
   ],
   "source": [
    "#Removing unnecessary columns from the dataset \"global_temps\"\n",
    "dataset_3.columns = dataset_3.columns.str.strip()\n",
    "dropping_3 = [\"J-D\", \"D-N\", \"DJF\", \"MAM\", \"JJA\", \"SON\"]\n",
    "dataset_3.drop(columns=dropping_3, inplace= True, errors= \"ignore\")\n",
    "\n",
    "#updating the csv\n",
    "dataset_3.to_csv(\"global_temps.csv\", index= False)\n",
    "print(\"global_temps dataset, has been updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432aec3e",
   "metadata": {},
   "source": [
    "Cleaning the data by replacing nan values with approprate values for the specific column, by first identifying where the nan values are in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04c3c810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values from Dataset 1: CO2 emission by countries\n",
      "Year                   0\n",
      "CO2 emission (Tons)    0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Missing values from Dataset 2: Historical Tropical Storm\n",
      "YEAR          0\n",
      "MONTH         0\n",
      "DAY           0\n",
      "LAT           0\n",
      "LONG          0\n",
      "WIND_KTS      0\n",
      "PRESSURE      0\n",
      "CAT           0\n",
      "Shape_Leng    0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Missing values from Dataset 3: global_temps\n",
      "Year    0\n",
      "Jan     0\n",
      "Feb     0\n",
      "Mar     0\n",
      "Apr     0\n",
      "May     0\n",
      "Jun     1\n",
      "Jul     1\n",
      "Aug     1\n",
      "Sep     1\n",
      "Oct     1\n",
      "Nov     1\n",
      "Dec     1\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Identify the number of missing values in the datasets\n",
    "print(\"Missing values from Dataset 1: CO2 emission by countries\")\n",
    "print(dataset_1.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Missing values from Dataset 2: Historical Tropical Storm\")\n",
    "print(dataset_2.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Missing values from Dataset 3: global_temps\")\n",
    "print(dataset_3.isnull().sum())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64b40032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values from Dataset 3: global_temps\n",
      "Year    0\n",
      "Jan     0\n",
      "Feb     0\n",
      "Mar     0\n",
      "Apr     0\n",
      "May     0\n",
      "Jun     0\n",
      "Jul     0\n",
      "Aug     0\n",
      "Sep     0\n",
      "Oct     0\n",
      "Nov     0\n",
      "Dec     0\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Cleaning the global_temps dataset\n",
    "\n",
    "#Filling in all nan values with the avarage value of their column\n",
    "find_avg_value= [\"Jun\",\"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "\n",
    "#temp assigning the nan values to 0 for the summing\n",
    "dataset_3[find_avg_value] = dataset_3[find_avg_value].fillna(0)\n",
    "\n",
    "#casting to float\n",
    "dataset_3[find_avg_value] = dataset_3[find_avg_value].astype(float)\n",
    "\n",
    "agv_value = dataset_3[find_avg_value].mean()\n",
    "dataset_3[find_avg_value] = dataset_3[find_avg_value].fillna(agv_value) \n",
    "\n",
    "\n",
    "#Updating the dataset_3 csv\n",
    "dataset_3.to_csv(\"global_temps.csv\", index= False)\n",
    "\n",
    "#Testing if the change was made\n",
    "print(\"Missing values from Dataset 3: global_temps\")\n",
    "print(dataset_3.isnull().sum())\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06353350",
   "metadata": {},
   "source": [
    "Checking if the current data types for all attributes in all datasets are of the correct types for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788832fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59620 entries, 0 to 59619\n",
      "Data columns (total 2 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Year                 59620 non-null  int64  \n",
      " 1   CO2 emission (Tons)  59620 non-null  float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 931.7 KB\n"
     ]
    }
   ],
   "source": [
    "#dataset_1\n",
    "\n",
    "#Before \n",
    "dataset_1.info()\n",
    "\n",
    "#The dataset is of the correct types, no chanages to be done here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04baa383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59228 entries, 0 to 59227\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   YEAR        59228 non-null  int64  \n",
      " 1   MONTH       59228 non-null  int64  \n",
      " 2   DAY         59228 non-null  int64  \n",
      " 3   LAT         59228 non-null  float64\n",
      " 4   LONG        59228 non-null  float64\n",
      " 5   WIND_KTS    59228 non-null  int64  \n",
      " 6   PRESSURE    59228 non-null  int64  \n",
      " 7   CAT         59228 non-null  object \n",
      " 8   Shape_Leng  59228 non-null  float64\n",
      "dtypes: float64(3), int64(5), object(1)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#dataset_2\n",
    "\n",
    "#Before \n",
    "dataset_2.info()\n",
    "\n",
    "#The dataset is of the correct types, no chanages to be done here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bbde84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144 entries, 0 to 143\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Year    144 non-null    int64  \n",
      " 1   Jan     144 non-null    float64\n",
      " 2   Feb     144 non-null    float64\n",
      " 3   Mar     144 non-null    float64\n",
      " 4   Apr     144 non-null    float64\n",
      " 5   May     144 non-null    float64\n",
      " 6   Jun     144 non-null    float64\n",
      " 7   Jul     144 non-null    float64\n",
      " 8   Aug     144 non-null    float64\n",
      " 9   Sep     144 non-null    float64\n",
      " 10  Oct     144 non-null    float64\n",
      " 11  Nov     144 non-null    float64\n",
      " 12  Dec     144 non-null    float64\n",
      "dtypes: float64(12), int64(1)\n",
      "memory usage: 14.8 KB\n"
     ]
    }
   ],
   "source": [
    "#dataset_3\n",
    "\n",
    "dataset_3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240668ac",
   "metadata": {},
   "source": [
    "Merging the 3 datasets together, dataset_2 \"Historical Tropical Storm\" with joining dataset_1 \"CO2 emission by countries\" using their year attribute, then taking the joined datasets and connecting it to \"global_temps\" using the year attribute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21d9e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Dataset of Historical Tropical Storm and CO2 emission by countries\n",
      "   Year  MONTH  DAY   LAT  LONG  WIND_KTS  PRESSURE CAT  Shape_Leng  \\\n",
      "0  1851      7    5  22.2 -97.6        80         0  H1    0.141421   \n",
      "1  1851      7    5  22.2 -97.6        80         0  H1    0.141421   \n",
      "2  1851      7    5  22.2 -97.6        80         0  H1    0.141421   \n",
      "3  1851      7    5  22.2 -97.6        80         0  H1    0.141421   \n",
      "4  1851      7    5  22.2 -97.6        80         0  H1    0.141421   \n",
      "\n",
      "   CO2 emission (Tons)  \n",
      "0                  0.0  \n",
      "1                  0.0  \n",
      "2                  0.0  \n",
      "3                  0.0  \n",
      "4                  0.0  \n",
      "   Year  MONTH  DAY   LAT  LONG  WIND_KTS  PRESSURE CAT  Shape_Leng  \\\n",
      "0  1851      7    5  22.2 -97.6        80         0  H1    0.141421   \n",
      "1  1851      7    5  22.2 -97.6        80         0  H1    0.141421   \n",
      "2  1851      7    5  22.2 -97.6        80         0  H1    0.141421   \n",
      "3  1851      7    5  22.2 -97.6        80         0  H1    0.141421   \n",
      "4  1851      7    5  22.2 -97.6        80         0  H1    0.141421   \n",
      "\n",
      "   CO2 emission (Tons)  ...  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec  \n",
      "0                  0.0  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1                  0.0  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "2                  0.0  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "3                  0.0  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "4                  0.0  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#creating and writing to a new csv\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted_dataset_for_IS_project_25.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m---> 15\u001b[0m     writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(file)\n\u001b[0;32m     16\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriterow(final_dataset\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m final_dataset\u001b[38;5;241m.\u001b[39miterrows():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'csv' is not defined"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "#changing the attribute names to match where the are being joined\n",
    "dataset_2 = dataset_2.rename(columns={\"YEAR\": \"Year\"})\n",
    "\n",
    "dataset_4 = pd.merge(dataset_2, dataset_1, on= \"Year\", how= \"left\") #left for keeping all data from dataset_1\n",
    "\n",
    "print(\"Merged Dataset of Historical Tropical Storm and CO2 emission by countries\")\n",
    "print(dataset_4.head(5))\n",
    "\n",
    "final_dataset = pd.merge(dataset_4, dataset_3, on= \"Year\", how= \"left\") #left for keeping all data from dataset_4\n",
    "print(final_dataset.head(5))\n",
    "\n",
    "#creating and writing to a new csv\n",
    "\n",
    "with open(\"completed_dataset_for_IS_project_25.csv\", 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(final_dataset.columns)\n",
    "\n",
    "    for index, row in final_dataset.iterrows():\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"Final Dataset csv has been created\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
