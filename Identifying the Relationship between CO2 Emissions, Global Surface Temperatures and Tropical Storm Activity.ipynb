{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef8a598-e077-4e6b-a06d-1b9f99932765",
   "metadata": {},
   "source": [
    "Loading the dataset csv's into data frames and printing the first 10 values in the data set for each data frame to ensure that the data is being read and stored correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8292e8cb-ab63-426b-b2f1-71bfdae3746a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From Dataset 1: CO2 emission by countries\n",
      "       Country  Year  CO2 emission (Tons)\n",
      "0  Afghanistan  1750                  0.0\n",
      "1  Afghanistan  1751                  0.0\n",
      "2  Afghanistan  1752                  0.0\n",
      "3  Afghanistan  1753                  0.0\n",
      "4  Afghanistan  1754                  0.0\n",
      "5  Afghanistan  1755                  0.0\n",
      "6  Afghanistan  1756                  0.0\n",
      "7  Afghanistan  1757                  0.0\n",
      "8  Afghanistan  1758                  0.0\n",
      "9  Afghanistan  1759                  0.0\n",
      "\n",
      "\n",
      "From Dataset 2: Historical Tropical Storm\n",
      "   YEAR  MONTH  DAY   LAT  LONG  WIND_KTS  PRESSURE CAT  Shape_Leng Country\n",
      "0  1851      7    5  22.2 -97.6        80         0  H1    0.141421  Mexico\n",
      "1  1851      8   21  23.2 -82.5        60         0  TS    1.303840    Cuba\n",
      "2  1851      8   21  23.9 -83.6        70         0  H1    0.860233    Cuba\n",
      "3  1851      8   20  21.2 -79.0        70         0  H1    1.565248    Cuba\n",
      "4  1851      8   20  21.9 -80.4        70         0  H1    1.220656    Cuba\n",
      "5  1851      8   21  22.6 -81.4        60         0  TS    1.252996    Cuba\n",
      "6  1851      8   20  19.9 -75.9        70         0  H1    1.802776    Cuba\n",
      "7  1851      8   20  20.5 -77.6        70         0  H1    1.565248    Cuba\n",
      "8  1851      8   19  18.9 -72.6        60         0  TS    1.772005   Haiti\n",
      "9  1851      8   19  19.4 -74.3        60         0  TS    1.676305   Haiti\n",
      "\n",
      "\n",
      "From Dataset 3: global_temps\n",
      "   Year   Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov  \\\n",
      "0  1880 -0.19 -0.25 -0.09 -0.17 -0.10 -0.21 -0.18 -0.11 -0.15 -0.24 -0.22   \n",
      "1  1881 -0.20 -0.15  0.03  0.05  0.05 -0.19  0.00 -0.04 -0.16 -0.22 -0.19   \n",
      "2  1882  0.16  0.13  0.04 -0.16 -0.14 -0.22 -0.17 -0.08 -0.15 -0.24 -0.17   \n",
      "3  1883 -0.30 -0.37 -0.13 -0.19 -0.18 -0.08 -0.08 -0.14 -0.23 -0.12 -0.24   \n",
      "4  1884 -0.13 -0.09 -0.37 -0.40 -0.34 -0.35 -0.31 -0.28 -0.28 -0.25 -0.34   \n",
      "5  1885 -0.59 -0.34 -0.27 -0.42 -0.45 -0.44 -0.34 -0.32 -0.29 -0.24 -0.24   \n",
      "6  1886 -0.44 -0.51 -0.43 -0.28 -0.24 -0.35 -0.18 -0.31 -0.24 -0.28 -0.28   \n",
      "7  1887 -0.72 -0.57 -0.36 -0.35 -0.31 -0.25 -0.26 -0.36 -0.26 -0.36 -0.27   \n",
      "8  1888 -0.34 -0.36 -0.41 -0.20 -0.22 -0.17 -0.11 -0.16 -0.12  0.01  0.03   \n",
      "9  1889 -0.09  0.16  0.06  0.10 -0.01 -0.10 -0.08 -0.20 -0.24 -0.25 -0.33   \n",
      "\n",
      "    Dec  \n",
      "0 -0.18  \n",
      "1 -0.08  \n",
      "2 -0.36  \n",
      "3 -0.11  \n",
      "4 -0.31  \n",
      "5 -0.11  \n",
      "6 -0.26  \n",
      "7 -0.33  \n",
      "8 -0.04  \n",
      "9 -0.29  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_1 = pd.read_csv(\"CO2 emission by countries.csv\")\n",
    "dataset_2 = pd.read_csv(\"Historical Tropical Storm.csv\")\n",
    "dataset_3 = pd.read_csv(\"global_temps.csv\")\n",
    "\n",
    "print(\"From Dataset 1: CO2 emission by countries\")\n",
    "print(dataset_1.head(10))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"From Dataset 2: Historical Tropical Storm\")\n",
    "print(dataset_2.head(10))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"From Dataset 3: global_temps\")\n",
    "print(dataset_3.head(10))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0d0603",
   "metadata": {},
   "source": [
    "The \"CO2 emission by countries\" dataset currently has these attributes: \"Code\", \"Calling Code\", \"Year\", \"CO2 emission (Tons)\", \"Population(2022)\", \"Area\", \"% of World\" and \"Density(km2)\" but from this dataset we only require \"Country\", \"Year\" and \"CO2 emission (Tons)\" so the others will be removed to reduce the size of the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3959baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CO2 emission by countries dataset, has been updated\n"
     ]
    }
   ],
   "source": [
    "#Removing unnecessary columns from the datasets \"CO2 emission by countries\"\n",
    "dataset_1.columns = dataset_1.columns.str.strip()\n",
    "dropping = [\"Code\", \"Calling Code\", \"Population(2022)\", \"Area\", \"% of World\", \"Density(km2)\"]\n",
    "dataset_1.drop(columns=dropping, inplace= True, errors= \"ignore\")\n",
    "\n",
    "#updating the csv\n",
    "dataset_1.to_csv(\"CO2 emission by countries.csv\", index= False)\n",
    "print(\"CO2 emission by countries dataset, has been updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b113e8a0",
   "metadata": {},
   "source": [
    "We will now use the Geopy module to deduce the countries where the Historical Tropical storms occured based on the Latitude and Longititude provided. This will be of use later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12163a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import reverse_geocoder as rg\n",
    "import pycountry\n",
    "# !pip install reverse_geocoder\n",
    "geolocator = Nominatim(user_agent=\"my_geopy_app\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728045d",
   "metadata": {},
   "source": [
    "Function to extract country name from pycountry response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68831c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_name(code):\n",
    "    try:\n",
    "        return pycountry.countries.get(alpha_2=code).name\n",
    "    except:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cee32451",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = list(zip(dataset_2['LAT'], dataset_2['LONG']))\n",
    "\n",
    "# Run reverse geocoding in bulk\n",
    "results = rg.search(coords)  # returns list of dicts with keys like 'cc' (country code), 'name', etc.\n",
    "\n",
    "# Extract country info\n",
    "country_names = [res['cc'] for res in results]  # you can also use res['name'] or 'admin1' if needed\n",
    "\n",
    "country_full_names = [get_country_name(code) for code in country_names]\n",
    "\n",
    "# Add to DataFrame\n",
    "dataset_2[\"Country\"] = country_full_names\n",
    "\n",
    "# Save result\n",
    "# dataset_2.to_csv(\"Historical Tropical Storm-v2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910a272e",
   "metadata": {},
   "source": [
    "The \"Historical Tropical Storm\" dataset currently has these attributes: \"FID\", \"YEAR\", \"MONTH\", \"DAY\", \"AD_TIME\", \"BTID\", \"NAME\", \"LAT\", \"LONG\", \"WIND_KTS\", \"PRESSURE\", \"CAT\", \"BASIN\" and \"Shape_Leng\" but from this dataset we only require \"YEAR\", \"MONTH\", \"DAY\", \"LAT\", \"LONG\", \"WIND_KTS\", \"PRESSURE\", \"CAT\" and \"Shape_Leng\" so the others will be removed to reduce the size of the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "045d8cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical Tropical Storm dataset, has been updated\n"
     ]
    }
   ],
   "source": [
    "#Removing unnecessary columns from the dataset \"Historical Tropical Storm\"\n",
    "dataset_2.columns = dataset_2.columns.str.strip()\n",
    "dropping_2 = [\"FID\", \"AD_TIME\", \"BTID\", \"NAME\", \"BASIN\"]\n",
    "dataset_2.drop(columns=dropping_2, inplace= True, errors= \"ignore\")\n",
    "\n",
    "#updating the csv\n",
    "dataset_2.to_csv(\"Historical Tropical Storm.csv\", index= False)\n",
    "print(\"Historical Tropical Storm dataset, has been updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4582ef54",
   "metadata": {},
   "source": [
    "The \"global_temps\" dataset currently has these attributes: \"Year\", \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\", \"J-D\", \"D-N\", \"DJF\", \"MAM\", \"JJA\" and \"SON\" but from this dataset we only require \"Year\", \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\"and \"Dec\" so the others will be removed to reduce the size of the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5949d2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_temps dataset, has been updated\n"
     ]
    }
   ],
   "source": [
    "#Removing unnecessary columns from the dataset \"global_temps\"\n",
    "dataset_3.columns = dataset_3.columns.str.strip()\n",
    "dropping_3 = [\"J-D\", \"D-N\", \"DJF\", \"MAM\", \"JJA\", \"SON\"]\n",
    "dataset_3.drop(columns=dropping_3, inplace= True, errors= \"ignore\")\n",
    "\n",
    "#updating the csv\n",
    "dataset_3.to_csv(\"global_temps.csv\", index= False)\n",
    "print(\"global_temps dataset, has been updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432aec3e",
   "metadata": {},
   "source": [
    "Cleaning the data by replacing nan values with approprate values for the specific column, by first identifying where the nan values are in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04c3c810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values from Dataset 1: CO2 emission by countries\n",
      "Country                0\n",
      "Year                   0\n",
      "CO2 emission (Tons)    0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Missing values from Dataset 2: Historical Tropical Storm\n",
      "YEAR          0\n",
      "MONTH         0\n",
      "DAY           0\n",
      "LAT           0\n",
      "LONG          0\n",
      "WIND_KTS      0\n",
      "PRESSURE      0\n",
      "CAT           0\n",
      "Shape_Leng    0\n",
      "Country       0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Missing values from Dataset 3: global_temps\n",
      "Year    0\n",
      "Jan     0\n",
      "Feb     0\n",
      "Mar     0\n",
      "Apr     0\n",
      "May     0\n",
      "Jun     0\n",
      "Jul     0\n",
      "Aug     0\n",
      "Sep     0\n",
      "Oct     0\n",
      "Nov     0\n",
      "Dec     0\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Identify the number of missing values in the datasets\n",
    "print(\"Missing values from Dataset 1: CO2 emission by countries\")\n",
    "print(dataset_1.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Missing values from Dataset 2: Historical Tropical Storm\")\n",
    "print(dataset_2.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Missing values from Dataset 3: global_temps\")\n",
    "print(dataset_3.isnull().sum())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64b40032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values from Dataset 3: global_temps\n",
      "Year    0\n",
      "Jan     0\n",
      "Feb     0\n",
      "Mar     0\n",
      "Apr     0\n",
      "May     0\n",
      "Jun     0\n",
      "Jul     0\n",
      "Aug     0\n",
      "Sep     0\n",
      "Oct     0\n",
      "Nov     0\n",
      "Dec     0\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Cleaning the global_temps dataset\n",
    "\n",
    "#Filling in all nan values with the avarage value of their column\n",
    "find_avg_value= [\"Jun\",\"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "\n",
    "#temp assigning the nan values to 0 for the summing\n",
    "dataset_3[find_avg_value] = dataset_3[find_avg_value].fillna(0)\n",
    "\n",
    "#casting to float\n",
    "dataset_3[find_avg_value] = dataset_3[find_avg_value].astype(float)\n",
    "\n",
    "agv_value = dataset_3[find_avg_value].mean()\n",
    "dataset_3[find_avg_value] = dataset_3[find_avg_value].fillna(agv_value) \n",
    "\n",
    "\n",
    "#Updating the dataset_3 csv\n",
    "dataset_3.to_csv(\"global_temps.csv\", index= False)\n",
    "\n",
    "#Testing if the change was made\n",
    "print(\"Missing values from Dataset 3: global_temps\")\n",
    "print(dataset_3.isnull().sum())\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06353350",
   "metadata": {},
   "source": [
    "Checking if the current data types for all attributes in all datasets are of the correct types for further processing. To further reduce the size of the final dataset I will be down casting the datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "788832fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59620 entries, 0 to 59619\n",
      "Data columns (total 3 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Country              59620 non-null  object \n",
      " 1   Year                 59620 non-null  int64  \n",
      " 2   CO2 emission (Tons)  59620 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 1.4+ MB\n",
      "\n",
      "\n",
      "After\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59620 entries, 0 to 59619\n",
      "Data columns (total 3 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Country              59620 non-null  object \n",
      " 1   Year                 59620 non-null  int32  \n",
      " 2   CO2 emission (Tons)  59620 non-null  float32\n",
      "dtypes: float32(1), int32(1), object(1)\n",
      "memory usage: 931.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#dataset_1\n",
    "\n",
    "#Before\n",
    "print(\"Before\") \n",
    "dataset_1.info()\n",
    "print(\"\\n\")\n",
    "\n",
    "#Down casting\n",
    "dataset_1[\"Year\"] = dataset_1[\"Year\"].astype(\"int32\")\n",
    "dataset_1[\"CO2 emission (Tons)\"] = dataset_1[\"CO2 emission (Tons)\"].astype(\"float32\")\n",
    "\n",
    "#Updating the dataset_1 csv\n",
    "dataset_1.to_csv(\"CO2 emission by countries.csv\", index= False)\n",
    "\n",
    "#After\n",
    "print(\"After\") \n",
    "dataset_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04baa383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59228 entries, 0 to 59227\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   YEAR        59228 non-null  int64  \n",
      " 1   MONTH       59228 non-null  int64  \n",
      " 2   DAY         59228 non-null  int64  \n",
      " 3   LAT         59228 non-null  float64\n",
      " 4   LONG        59228 non-null  float64\n",
      " 5   WIND_KTS    59228 non-null  int64  \n",
      " 6   PRESSURE    59228 non-null  int64  \n",
      " 7   CAT         59228 non-null  object \n",
      " 8   Shape_Leng  59228 non-null  float64\n",
      " 9   Country     59228 non-null  object \n",
      "dtypes: float64(3), int64(5), object(2)\n",
      "memory usage: 4.5+ MB\n",
      "\n",
      "\n",
      "After\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59228 entries, 0 to 59227\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   YEAR        59228 non-null  int32  \n",
      " 1   MONTH       59228 non-null  int32  \n",
      " 2   DAY         59228 non-null  int32  \n",
      " 3   LAT         59228 non-null  float32\n",
      " 4   LONG        59228 non-null  float32\n",
      " 5   WIND_KTS    59228 non-null  int32  \n",
      " 6   PRESSURE    59228 non-null  int32  \n",
      " 7   CAT         59228 non-null  object \n",
      " 8   Shape_Leng  59228 non-null  float32\n",
      " 9   Country     59228 non-null  object \n",
      "dtypes: float32(3), int32(5), object(2)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#dataset_2\n",
    "\n",
    "#Before \n",
    "print(\"Before\") \n",
    "dataset_2.info()\n",
    "print(\"\\n\")\n",
    "\n",
    "#Down casting\n",
    "to_int_32 = [\"YEAR\", \"MONTH\", \"DAY\", \"WIND_KTS\", \"PRESSURE\"]\n",
    "dataset_2[to_int_32 ] = dataset_2[to_int_32 ].astype(\"int32\")\n",
    "\n",
    "to_float_32 = [\"LAT\", \"LONG\", \"Shape_Leng\"]\n",
    "dataset_2[to_float_32] = dataset_2[to_float_32].astype(\"float32\")\n",
    "\n",
    "#Updating the dataset_1 csv\n",
    "dataset_2.to_csv(\"Historical Tropical Storm.csv\", index= False)\n",
    "\n",
    "#After\n",
    "print(\"After\") \n",
    "dataset_2.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bbde84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144 entries, 0 to 143\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Year    144 non-null    int64  \n",
      " 1   Jan     144 non-null    float64\n",
      " 2   Feb     144 non-null    float64\n",
      " 3   Mar     144 non-null    float64\n",
      " 4   Apr     144 non-null    float64\n",
      " 5   May     144 non-null    float64\n",
      " 6   Jun     144 non-null    float64\n",
      " 7   Jul     144 non-null    float64\n",
      " 8   Aug     144 non-null    float64\n",
      " 9   Sep     144 non-null    float64\n",
      " 10  Oct     144 non-null    float64\n",
      " 11  Nov     144 non-null    float64\n",
      " 12  Dec     144 non-null    float64\n",
      "dtypes: float64(12), int64(1)\n",
      "memory usage: 14.8 KB\n",
      "\n",
      "\n",
      "After\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144 entries, 0 to 143\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Year    144 non-null    int32  \n",
      " 1   Jan     144 non-null    float32\n",
      " 2   Feb     144 non-null    float32\n",
      " 3   Mar     144 non-null    float32\n",
      " 4   Apr     144 non-null    float32\n",
      " 5   May     144 non-null    float32\n",
      " 6   Jun     144 non-null    float32\n",
      " 7   Jul     144 non-null    float32\n",
      " 8   Aug     144 non-null    float32\n",
      " 9   Sep     144 non-null    float32\n",
      " 10  Oct     144 non-null    float32\n",
      " 11  Nov     144 non-null    float32\n",
      " 12  Dec     144 non-null    float32\n",
      "dtypes: float32(12), int32(1)\n",
      "memory usage: 7.4 KB\n"
     ]
    }
   ],
   "source": [
    "#dataset_3\n",
    "\n",
    "#Before \n",
    "print(\"Before\") \n",
    "dataset_3.info()\n",
    "print(\"\\n\")\n",
    "\n",
    "#Down casting\n",
    "dataset_3[\"Year\"] = dataset_3[\"Year\"].astype(\"int32\")\n",
    "\n",
    "to_float_32_d3 = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "dataset_3[to_float_32_d3] = dataset_3[to_float_32_d3].astype(\"float32\")\n",
    "\n",
    "#Updating the dataset_1 csv\n",
    "dataset_3.to_csv(\"global_temps.csv\", index= False)\n",
    "\n",
    "#After\n",
    "print(\"After\") \n",
    "dataset_3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240668ac",
   "metadata": {},
   "source": [
    "Merging the 3 datasets together, dataset_2 \"Historical Tropical Storm\" with joining dataset_1 \"CO2 emission by countries\" using their year attribute, then taking the joined datasets and connecting it to \"global_temps\" using the year attribute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c21d9e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Dataset of Historical Tropical Storm and CO2 emission by countries\n",
      "   Year  MONTH  DAY        LAT       LONG  WIND_KTS  PRESSURE CAT  Shape_Leng  \\\n",
      "0  1851      7    5  22.200001 -97.599998        80         0  H1    0.141421   \n",
      "1  1851      8   21  23.200001 -82.500000        60         0  TS    1.303840   \n",
      "2  1851      8   21  23.900000 -83.599998        70         0  H1    0.860233   \n",
      "3  1851      8   20  21.200001 -79.000000        70         0  H1    1.565248   \n",
      "4  1851      8   20  21.900000 -80.400002        70         0  H1    1.220656   \n",
      "\n",
      "  Country  CO2 emission (Tons)  \n",
      "0  Mexico                  0.0  \n",
      "1    Cuba                  0.0  \n",
      "2    Cuba                  0.0  \n",
      "3    Cuba                  0.0  \n",
      "4    Cuba                  0.0  \n",
      "Sample of the Final Dataset\n",
      "   Year  MONTH  DAY        LAT       LONG  WIND_KTS  PRESSURE CAT  Shape_Leng  \\\n",
      "0  1851      7    5  22.200001 -97.599998        80         0  H1    0.141421   \n",
      "1  1851      8   21  23.200001 -82.500000        60         0  TS    1.303840   \n",
      "2  1851      8   21  23.900000 -83.599998        70         0  H1    0.860233   \n",
      "3  1851      8   20  21.200001 -79.000000        70         0  H1    1.565248   \n",
      "4  1851      8   20  21.900000 -80.400002        70         0  H1    1.220656   \n",
      "\n",
      "  Country  ...  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec  \n",
      "0  Mexico  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1    Cuba  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "2    Cuba  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "3    Cuba  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "4    Cuba  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Final Dataset csv has been created\n"
     ]
    }
   ],
   "source": [
    "#import csv\n",
    "\n",
    "#changing the attribute names to match where the are being joined\n",
    "dataset_2 = dataset_2.rename(columns={\"YEAR\": \"Year\"})\n",
    "\n",
    "dataset_4 = dataset_2.merge(dataset_1, on= [\"Year\",\"Country\"], how= \"left\") #left for keeping all data from dataset_1, now merges based on the country name and year\n",
    "# dataset_4 = pd.merge(dataset_1, dataset_2, on= [\"Year\",\"Country\"])\n",
    "\n",
    "print(\"Merged Dataset of Historical Tropical Storm and CO2 emission by countries\")\n",
    "print(dataset_4.head(5))\n",
    "\n",
    "final_dataset = dataset_4.merge(dataset_3, on= \"Year\", how= \"left\") #left for keeping all data from dataset_4\n",
    "\n",
    "print(\"Sample of the Final Dataset\")\n",
    "print(final_dataset.head(5))\n",
    "\n",
    "#creating and writing to a new csv\n",
    "final_dataset.to_csv(\"completed_dataset_for_IS_project_25.csv\", index= False, encoding= \"utf-8\")\n",
    "\n",
    "print(\"Final Dataset csv has been created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306e3ac7",
   "metadata": {},
   "source": [
    "The merged data set currently has 1,048,576 rows, I'm going to remove te rows that lacks the necessary information further reducing the size of the dataset\n",
    "\n",
    "The necessary columns are:  \"Year\", \"MONTH\", \"DAY\", \"LAT\", \"LONG\", \"WIND_KTS\", \"PRESSURE\", \"CAT\", \"Shape_Leng\", \"CO2 emission (Tons)\", \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\" and \"Dec\"\n",
    "\n",
    "If any data is missing then remove that row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a252274e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of the final dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Year  MONTH  DAY   LAT  LONG  WIND_KTS  PRESSURE CAT  Shape_Leng  \\\n",
      "3520  1880      8   11  23.0 -91.9        70         0  H1    0.806226   \n",
      "3521  1880      8   11  23.4 -92.6        80         0  H1    0.761577   \n",
      "3522  1880      8   11  23.7 -93.3        80         0  H1    0.583095   \n",
      "3523  1880      8   12  24.0 -93.8        90         0  H2    0.670820   \n",
      "3524  1880      9    6  23.9 -88.6        40         0  TS    0.360555   \n",
      "\n",
      "     Country  ...   Mar   Apr  May   Jun   Jul   Aug   Sep   Oct   Nov   Dec  \n",
      "3520  Mexico  ... -0.09 -0.17 -0.1 -0.21 -0.18 -0.11 -0.15 -0.24 -0.22 -0.18  \n",
      "3521  Mexico  ... -0.09 -0.17 -0.1 -0.21 -0.18 -0.11 -0.15 -0.24 -0.22 -0.18  \n",
      "3522  Mexico  ... -0.09 -0.17 -0.1 -0.21 -0.18 -0.11 -0.15 -0.24 -0.22 -0.18  \n",
      "3523  Mexico  ... -0.09 -0.17 -0.1 -0.21 -0.18 -0.11 -0.15 -0.24 -0.22 -0.18  \n",
      "3524  Mexico  ... -0.09 -0.17 -0.1 -0.21 -0.18 -0.11 -0.15 -0.24 -0.22 -0.18  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "The dataset is ready for processing\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "necessary_columns = [\"Year\", \"MONTH\", \"DAY\", \"LAT\", \"LONG\", \"WIND_KTS\", \"PRESSURE\", \"CAT\", \"Shape_Leng\", \"Country\", \"CO2 emission (Tons)\", \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "\n",
    "#made more efficient and reduces the amount of memory used\n",
    "large_dataset = dd.read_csv(\"completed_dataset_for_IS_project_25.csv\", usecols=necessary_columns)\n",
    "\n",
    "cleaned_final_dataset = large_dataset.dropna(subset=necessary_columns)\n",
    "\n",
    "print(\"Sample of the final dataset\")\n",
    "print(cleaned_final_dataset.head(5))\n",
    "\n",
    "#Updating the dataset_3 csv - made more efficient\n",
    "cleaned_final_dataset.compute().to_csv(\"completed_dataset_for_IS_project_25.csv\", index= False)\n",
    "\n",
    "print(\"The dataset is ready for processing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9da7c71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values from Final Dataset\n",
      "Year                   0\n",
      "MONTH                  0\n",
      "DAY                    0\n",
      "LAT                    0\n",
      "LONG                   0\n",
      "WIND_KTS               0\n",
      "PRESSURE               0\n",
      "CAT                    0\n",
      "Shape_Leng             0\n",
      "Country                0\n",
      "CO2 emission (Tons)    0\n",
      "Jan                    0\n",
      "Feb                    0\n",
      "Mar                    0\n",
      "Apr                    0\n",
      "May                    0\n",
      "Jun                    0\n",
      "Jul                    0\n",
      "Aug                    0\n",
      "Sep                    0\n",
      "Oct                    0\n",
      "Nov                    0\n",
      "Dec                    0\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Testing to ensure no nan values in the dataset\n",
    "print(\"Missing values from Final Dataset\")\n",
    "print(cleaned_final_dataset.isna().sum().compute())\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb6dc24",
   "metadata": {},
   "source": [
    "Down casing the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1d6930e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 23 entries, Year to Dec\n",
      "dtypes: float64(16), int64(5), string(2)<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 23 entries, Year to Dec\n",
      "dtypes: float32(16), int32(5), string(2)"
     ]
    }
   ],
   "source": [
    "#Before \n",
    "cleaned_final_dataset.info()\n",
    "\n",
    "#Down casting\n",
    "to_int_32_final = [\"Year\", \"MONTH\", \"DAY\", \"WIND_KTS\", \"PRESSURE\"]\n",
    "cleaned_final_dataset[to_int_32_final] = cleaned_final_dataset[to_int_32_final ].astype(\"int32\")\n",
    "\n",
    "to_float_32_final = [\"CO2 emission (Tons)\", \"LAT\", \"LONG\", \"Shape_Leng\", \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "cleaned_final_dataset[to_float_32_final] = cleaned_final_dataset[to_float_32_final].astype(\"float32\")\n",
    "\n",
    "#Updating the cleaned_final_dataset csv\n",
    "cleaned_final_dataset.compute().to_csv(\"completed_dataset_for_IS_project_25.csv\", index= False)\n",
    "\n",
    "#After\n",
    "cleaned_final_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2695ccfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From Data: Completed dataset\n",
      "   Year  MONTH  DAY   LAT  LONG  WIND_KTS  PRESSURE CAT  Shape_Leng Country  \\\n",
      "0  1880      8   11  23.0 -91.9        70         0  H1    0.806226  Mexico   \n",
      "1  1880      8   11  23.4 -92.6        80         0  H1    0.761577  Mexico   \n",
      "2  1880      8   11  23.7 -93.3        80         0  H1    0.583095  Mexico   \n",
      "3  1880      8   12  24.0 -93.8        90         0  H2    0.670820  Mexico   \n",
      "4  1880      9    6  23.9 -88.6        40         0  TS    0.360555  Mexico   \n",
      "5  1880      8   10  22.0 -89.6        60         0  TS    0.854400  Mexico   \n",
      "6  1880      8    9  21.0 -87.4        70         0  H1    0.761577  Mexico   \n",
      "7  1880      8   10  21.3 -88.1        60         0  TS    0.854400  Mexico   \n",
      "8  1880      8   10  21.6 -88.9        50         0  TS    0.806226  Mexico   \n",
      "9  1880     10    6  21.4 -87.3        50         0  TS    0.800000  Mexico   \n",
      "\n",
      "   ...   Mar   Apr  May   Jun   Jul   Aug   Sep   Oct   Nov   Dec  \n",
      "0  ... -0.09 -0.17 -0.1 -0.21 -0.18 -0.11 -0.15 -0.24 -0.22 -0.18  \n",
      "1  ... -0.09 -0.17 -0.1 -0.21 -0.18 -0.11 -0.15 -0.24 -0.22 -0.18  \n",
      "2  ... -0.09 -0.17 -0.1 -0.21 -0.18 -0.11 -0.15 -0.24 -0.22 -0.18  \n",
      "3  ... -0.09 -0.17 -0.1 -0.21 -0.18 -0.11 -0.15 -0.24 -0.22 -0.18  \n",
      "4  ... -0.09 -0.17 -0.1 -0.21 -0.18 -0.11 -0.15 -0.24 -0.22 -0.18  \n",
      "5  ... -0.09 -0.17 -0.1 -0.21 -0.18 -0.11 -0.15 -0.24 -0.22 -0.18  \n",
      "6  ... -0.09 -0.17 -0.1 -0.21 -0.18 -0.11 -0.15 -0.24 -0.22 -0.18  \n",
      "7  ... -0.09 -0.17 -0.1 -0.21 -0.18 -0.11 -0.15 -0.24 -0.22 -0.18  \n",
      "8  ... -0.09 -0.17 -0.1 -0.21 -0.18 -0.11 -0.15 -0.24 -0.22 -0.18  \n",
      "9  ... -0.09 -0.17 -0.1 -0.21 -0.18 -0.11 -0.15 -0.24 -0.22 -0.18  \n",
      "\n",
      "[10 rows x 23 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"completed_dataset_for_IS_project_25.csv\")\n",
    "\n",
    "print(\"From Data: Completed dataset\")\n",
    "print(data.head(10))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2e8842a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "52651    False\n",
       "52652    False\n",
       "52653    False\n",
       "52654    False\n",
       "52655    False\n",
       "Length: 52656, dtype: bool"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195ad64e",
   "metadata": {},
   "source": [
    "For finding how strong a storm was, the higher the value the stronger the storm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aa6da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "storm_intensity = []\n",
    "for index, row in data.iterrows():\n",
    "    stormIntensity = row[\"WIND_KTS\"] * row[\"Shape_Leng\"]\n",
    "    storm_intensity.append(stormIntensity)\n",
    "data[\"Sorm Intensity\"] = storm_intensity\n",
    "# data.to_csv(\"stom int.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1da2522f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H1' 'H2' 'TS' 'E' 'H3' 'H4' 'TD' 'H5' 'L' 'SS' 'SD' 'W']\n"
     ]
    }
   ],
   "source": [
    "print(data['CAT'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f9af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def categorize_storm_variable(abbreviation):\n",
    "#     if abbreviation == 'H1':\n",
    "#         return 'Hurricane Categroy 1'\n",
    "#     elif abbreviation == 'H2':\n",
    "#         return 'Hurricane Categroy 2'\n",
    "#     elif abbreviation == 'H3':\n",
    "#         return 'Hurricane Categroy 3'\n",
    "#     elif abbreviation == 'H4':\n",
    "#         return 'Hurricane Categroy 4'\n",
    "#     elif abbreviation == 'H5':\n",
    "#         return 'Hurricane Categroy 5'\n",
    "#     elif abbreviation == 'TS':\n",
    "#         return 'Tropical Storm'\n",
    "#     elif abbreviation == 'E':\n",
    "#         return 'Extra-tropical cyclone'\n",
    "#     elif abbreviation == 'W':\n",
    "#         return 'Warning'\n",
    "#     elif abbreviation == 'L':\n",
    "#         return 'Low-pressure system'\n",
    "#     elif abbreviation == 'SS':\n",
    "#         return 'Severe Storm'\n",
    "#     elif abbreviation == 'SD':\n",
    "#         return 'Subtropical Depression'\n",
    "#     elif abbreviation == 'TD':\n",
    "#         return 'Tropical Depression'\n",
    "#     else:\n",
    "#         return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7fd9de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_mapping = {\n",
    "    'L': 0,    # Low-pressure system\n",
    "    'TD': 1,   # Tropical Depression\n",
    "    'SD': 1,   # Subtropical Depression (or possibly 0.5)\n",
    "    'TS': 2,   # Tropical Storm\n",
    "    'SS': 2,   # Severe Storm (if equivalent to TS)\n",
    "    'H1': 3,   # Hurricane Category 1\n",
    "    'H2': 4,\n",
    "    'H3': 5,\n",
    "    'H4': 6,\n",
    "    'H5': 7,\n",
    "    'E': -1,   # Extra-tropical (non-standard storm)\n",
    "    'W': -2    # Warning flag, not intensity\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7177bdcc",
   "metadata": {},
   "source": [
    "For labelling each category of storm numerically for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c010c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Storm Intensity Label'] = data['CAT'].map(intensity_mapping)\n",
    "\n",
    "# data.to_csv(\"types of storms.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb28589b",
   "metadata": {},
   "source": [
    "For measuring the wind speed intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77d9c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Wind Speed Squared'] = data['WIND_KTS'] ** 2\n",
    "\n",
    "# data.to_csv(\"wind squared.csv\", index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
