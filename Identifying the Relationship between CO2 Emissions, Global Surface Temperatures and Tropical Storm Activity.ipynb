{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef8a598-e077-4e6b-a06d-1b9f99932765",
   "metadata": {},
   "source": [
    "Loading the dataset csv's into data frames and printing the first 10 values in the data set for each data frame to ensure that the data is being read and stored correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8292e8cb-ab63-426b-b2f1-71bfdae3746a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From Dataset 1: CO2 emission by countries\n",
      "       Country Code Calling Code  Year  CO2 emission (Tons)  Population(2022)  \\\n",
      "0  Afghanistan   AF           93  1750                  0.0        41128771.0   \n",
      "1  Afghanistan   AF           93  1751                  0.0        41128771.0   \n",
      "2  Afghanistan   AF           93  1752                  0.0        41128771.0   \n",
      "3  Afghanistan   AF           93  1753                  0.0        41128771.0   \n",
      "4  Afghanistan   AF           93  1754                  0.0        41128771.0   \n",
      "5  Afghanistan   AF           93  1755                  0.0        41128771.0   \n",
      "6  Afghanistan   AF           93  1756                  0.0        41128771.0   \n",
      "7  Afghanistan   AF           93  1757                  0.0        41128771.0   \n",
      "8  Afghanistan   AF           93  1758                  0.0        41128771.0   \n",
      "9  Afghanistan   AF           93  1759                  0.0        41128771.0   \n",
      "\n",
      "       Area % of World Density(km2)  \n",
      "0  652230.0      0.40%       63/km²  \n",
      "1  652230.0      0.40%       63/km²  \n",
      "2  652230.0      0.40%       63/km²  \n",
      "3  652230.0      0.40%       63/km²  \n",
      "4  652230.0      0.40%       63/km²  \n",
      "5  652230.0      0.40%       63/km²  \n",
      "6  652230.0      0.40%       63/km²  \n",
      "7  652230.0      0.40%       63/km²  \n",
      "8  652230.0      0.40%       63/km²  \n",
      "9  652230.0      0.40%       63/km²  \n",
      "\n",
      "\n",
      "From Dataset 2: Historical Tropical Storm\n",
      "     FID  YEAR  MONTH  DAY AD_TIME  BTID      NAME   LAT  LONG  WIND_KTS  \\\n",
      "0  18832  1851      7    5   1200Z     2  NOTNAMED  22.2 -97.6        80   \n",
      "1  22626  1851      8   21   0600Z     4  NOTNAMED  23.2 -82.5        60   \n",
      "2  22632  1851      8   21   1200Z     4  NOTNAMED  23.9 -83.6        70   \n",
      "3  23755  1851      8   20   1200Z     4  NOTNAMED  21.2 -79.0        70   \n",
      "4  23757  1851      8   20   1800Z     4  NOTNAMED  21.9 -80.4        70   \n",
      "5  23762  1851      8   21   0000Z     4  NOTNAMED  22.6 -81.4        60   \n",
      "6  24891  1851      8   20   0000Z     4  NOTNAMED  19.9 -75.9        70   \n",
      "7  24893  1851      8   20   0600Z     4  NOTNAMED  20.5 -77.6        70   \n",
      "8  25502  1851      8   19   1200Z     4  NOTNAMED  18.9 -72.6        60   \n",
      "9  25802  1851      8   19   1800Z     4  NOTNAMED  19.4 -74.3        60   \n",
      "\n",
      "   PRESSURE CAT           BASIN  Shape_Leng  \n",
      "0         0  H1  North Atlantic    0.141421  \n",
      "1         0  TS  North Atlantic    1.303840  \n",
      "2         0  H1  North Atlantic    0.860233  \n",
      "3         0  H1  North Atlantic    1.565248  \n",
      "4         0  H1  North Atlantic    1.220656  \n",
      "5         0  TS  North Atlantic    1.252996  \n",
      "6         0  H1  North Atlantic    1.802776  \n",
      "7         0  H1  North Atlantic    1.565248  \n",
      "8         0  TS  North Atlantic    1.772005  \n",
      "9         0  TS  North Atlantic    1.676305  \n",
      "\n",
      "\n",
      "From Dataset 3: global_temps\n",
      "   Year   Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov  \\\n",
      "0  1880 -0.19 -0.25 -0.09 -0.17 -0.10 -0.21 -0.18 -0.11 -0.15 -0.24 -0.22   \n",
      "1  1881 -0.20 -0.15  0.03  0.05  0.05 -0.19  0.00 -0.04 -0.16 -0.22 -0.19   \n",
      "2  1882  0.16  0.13  0.04 -0.16 -0.14 -0.22 -0.17 -0.08 -0.15 -0.24 -0.17   \n",
      "3  1883 -0.30 -0.37 -0.13 -0.19 -0.18 -0.08 -0.08 -0.14 -0.23 -0.12 -0.24   \n",
      "4  1884 -0.13 -0.09 -0.37 -0.40 -0.34 -0.35 -0.31 -0.28 -0.28 -0.25 -0.34   \n",
      "5  1885 -0.59 -0.34 -0.27 -0.42 -0.45 -0.44 -0.34 -0.32 -0.29 -0.24 -0.24   \n",
      "6  1886 -0.44 -0.51 -0.43 -0.28 -0.24 -0.35 -0.18 -0.31 -0.24 -0.28 -0.28   \n",
      "7  1887 -0.72 -0.57 -0.36 -0.35 -0.31 -0.25 -0.26 -0.36 -0.26 -0.36 -0.27   \n",
      "8  1888 -0.34 -0.36 -0.41 -0.20 -0.22 -0.17 -0.11 -0.16 -0.12  0.01  0.03   \n",
      "9  1889 -0.09  0.16  0.06  0.10 -0.01 -0.10 -0.08 -0.20 -0.24 -0.25 -0.33   \n",
      "\n",
      "    Dec   J-D   D-N   DJF   MAM   JJA   SON  \n",
      "0 -0.18 -0.17   NaN   NaN -0.12 -0.17 -0.20  \n",
      "1 -0.08 -0.09 -0.10 -0.18  0.04 -0.08 -0.19  \n",
      "2 -0.36 -0.11 -0.09  0.07 -0.09 -0.16 -0.19  \n",
      "3 -0.11 -0.18 -0.20 -0.34 -0.17 -0.10 -0.20  \n",
      "4 -0.31 -0.29 -0.27 -0.11 -0.37 -0.32 -0.29  \n",
      "5 -0.11 -0.34 -0.35 -0.41 -0.38 -0.36 -0.25  \n",
      "6 -0.26 -0.32 -0.30 -0.35 -0.32 -0.28 -0.27  \n",
      "7 -0.33 -0.37 -0.36 -0.52 -0.34 -0.29 -0.29  \n",
      "8 -0.04 -0.17 -0.20 -0.34 -0.28 -0.14 -0.03  \n",
      "9 -0.29 -0.11 -0.09  0.01  0.05 -0.13 -0.28  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_1 = pd.read_csv(\"CO2 emission by countries.csv\")\n",
    "dataset_2 = pd.read_csv(\"Historical Tropical Storm.csv\")\n",
    "dataset_3 = pd.read_csv(\"global_temps.csv\")\n",
    "\n",
    "print(\"From Dataset 1: CO2 emission by countries\")\n",
    "print(dataset_1.head(10))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"From Dataset 2: Historical Tropical Storm\")\n",
    "print(dataset_2.head(10))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"From Dataset 3: global_temps\")\n",
    "print(dataset_3.head(10))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0d0603",
   "metadata": {},
   "source": [
    "The \"CO2 emission by countries\" dataset currently has these attributes: Country\", \"Code\", \"Calling Code\", \"Year\", \"CO2 emission (Tons)\", \"Population(2022)\", \"Area\", \"% of World\" and \"Density(km2)\" but from this dataset we only require \"Year\" and \"CO2 emission (Tons)\" so the others will be removed to reduce the size of the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3959baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CO2 emission by countries dataset, has been updated\n"
     ]
    }
   ],
   "source": [
    "#Removing unnecessary colums from the datasets \"CO2 emission by countries\"\n",
    "dataset_1.columns = dataset_1.columns.str.strip()\n",
    "dropping = [\"Country\", \"Code\", \"Calling Code\", \"Population(2022)\", \"Area\", \"% of World\", \"Density(km2)\"]\n",
    "dataset_1.drop(columns=dropping, inplace= True, errors= \"ignore\")\n",
    "\n",
    "#updating the csv\n",
    "dataset_1.to_csv(\"CO2 emission by countries.csv\", index= False)\n",
    "print(\"CO2 emission by countries dataset, has been updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910a272e",
   "metadata": {},
   "source": [
    "The \"Historical Tropical Storm\" dataset currently has these attributes: \"FID\", \"YEAR\", \"MONTH\", \"DAY\", \"AD_TIME\", \"BTID\", \"NAME\", \"LAT\", \"LONG\", \"WIND_KTS\", \"PRESSURE\", \"CAT\", \"BASIN\" and \"Shape_Leng\" but from this dataset we only require \"YEAR\", \"MONTH\", \"DAY\", \"LAT\", \"LONG\", \"WIND_KTS\", \"PRESSURE\", \"CAT\" and \"Shape_Leng\" so the others will be removed to reduce the size of the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "045d8cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical Tropical Storm dataset, has been updated\n"
     ]
    }
   ],
   "source": [
    "#Removing unnecessary colums from the dataset \"Historical Tropical Storm\"\n",
    "dataset_2.columns = dataset_2.columns.str.strip()\n",
    "dropping_2 = [\"FID\", \"AD_TIME\", \"BTID\", \"NAME\", \"BASIN\"]\n",
    "dataset_2.drop(columns=dropping_2, inplace= True, errors= \"ignore\")\n",
    "\n",
    "#updating the csv\n",
    "dataset_2.to_csv(\"Historical Tropical Storm.csv\", index= False)\n",
    "print(\"Historical Tropical Storm dataset, has been updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4582ef54",
   "metadata": {},
   "source": [
    "The \"global_temps\" dataset currently has these attributes: \"Year\", \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\", \"J-D\", \"D-N\", \"DJF\", \"MAM\", \"JJA\" and \"SON\" but from this dataset we only require \"Year\", \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\"and \"Dec\" so the others will be removed to reduce the size of the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5949d2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_temps dataset, has been updated\n"
     ]
    }
   ],
   "source": [
    "#Removing unnecessary colums from the dataset \"global_temps\"\n",
    "dataset_3.columns = dataset_3.columns.str.strip()\n",
    "dropping_3 = [\"J-D\", \"D-N\", \"DJF\", \"MAM\", \"JJA\", \"SON\"]\n",
    "dataset_3.drop(columns=dropping_3, inplace= True, errors= \"ignore\")\n",
    "\n",
    "#updating the csv\n",
    "dataset_3.to_csv(\"global_temps.csv\", index= False)\n",
    "print(\"global_temps dataset, has been updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432aec3e",
   "metadata": {},
   "source": [
    "Cleaning the data by replacing nan values with approprate values for the specific column, by first identifying where the nan values are in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c3c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify the number of missing values in the datasets\n",
    "print(\"Missing values from Dataset 1: CO2 emission by countries\")\n",
    "print(dataset_1.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Missing values from Dataset 2: Historical Tropical Storm\")\n",
    "print(dataset_2.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Missing values from Dataset 3: global_temps\")\n",
    "print(dataset_3.isnull().sum())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4d4f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the nan values in the datasets for \"CO2 emission by countries\"\n",
    "\n",
    "#Identifying the categories in the \"Code\" column so I can match the format when filling in the nan values\n",
    "print(\"Unique Code Values\")\n",
    "print(dataset_1[\"Code\"].unique())\n",
    "print(\"n\")\n",
    "\n",
    "#Format 2 letters in all caps, if nan replace with \"XX\"\n",
    "dataset_1[\"Code\"] = dataset_1[\"Code\"].fillna(\"XX\") \n",
    "\n",
    "\n",
    "#Identifying the categories in the \"Calling Code\" column so I can match the format when filling in the nan values\n",
    "print(\"Unique Calling Code Values\")\n",
    "print(dataset_1[\"Calling Code\"].unique())\n",
    "print(\"n\")\n",
    "\n",
    "#Format 2 - 4 characters, if nan replace with \"000\"\n",
    "dataset_1[\"Calling Code\"] = dataset_1[\"Calling Code\"].fillna(\"000\") \n",
    "\n",
    "\n",
    "#Following the fomat I saw by overview the column, the values are int, I'll replace the missing population values with the avarage value of the population columns\n",
    "#Doing the same for the \"Area\" and \"% of World\"\n",
    "\n",
    "find_avg= [\"Population(2022)\", \"Area\"]#, \"% of World\"]\n",
    "\n",
    "#temp assigning the nan values to 0 for the summing\n",
    "dataset_1[find_avg] = dataset_1[find_avg].fillna(0)\n",
    "\n",
    "#casting to int\n",
    "dataset_1[find_avg] = dataset_1[find_avg].astype(int)\n",
    "\n",
    "agv = dataset_1[find_avg].mean()\n",
    "dataset_1[find_avg] = dataset_1[find_avg].fillna(agv) \n",
    "\n",
    "\n",
    "# \"% of World\" and \"Density(km2)\"\" seem to be of type string, replacing the nan values with \"Unknown\" <-- not feeling too sure about the method I used here\n",
    "nan_to_unknown= [\"% of World\", \"Density(km2)\"]\n",
    "dataset_1[nan_to_unknown] = dataset_1[nan_to_unknown].fillna(\"Unknown\")\n",
    "\n",
    "\n",
    "#Updating the dataset_1 csv\n",
    "dataset_1.to_csv(\"CO2 emission by countries.csv\", index= False)\n",
    "\n",
    "#Testing if the change was made\n",
    "print(\"Missing values from Dataset 1: CO2 emission by countries\")\n",
    "print(dataset_1.isnull().sum())\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b40032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the global_temps dataset\n",
    "\n",
    "\n",
    "#Filling in all nan values with the avarage value of their column\n",
    "find_avg_value= [\"Jun\",\"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\", \"J-D\", \"D-N\", \"DJF\", \"JJA\", \"SON\"]\n",
    "\n",
    "#temp assigning the nan values to 0 for the summing\n",
    "dataset_3[find_avg_value] = dataset_3[find_avg_value].fillna(0)\n",
    "\n",
    "#casting to float\n",
    "dataset_3[find_avg_value] = dataset_3[find_avg_value].astype(float)\n",
    "\n",
    "agv_value = dataset_3[find_avg_value].mean()\n",
    "dataset_3[find_avg_value] = dataset_3[find_avg_value].fillna(agv_value) \n",
    "\n",
    "\n",
    "#Updating the dataset_3 csv\n",
    "dataset_3.to_csv(\"global_temps.csv\", index= False)\n",
    "\n",
    "#Testing if the change was made\n",
    "print(\"Missing values from Dataset 3: global_temps\")\n",
    "print(dataset_3.isnull().sum())\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240668ac",
   "metadata": {},
   "source": [
    "Merging the 3 datasets together, joining dataset_1 \"CO2 emission by countries\" with dataset_2 \"Historical Tropical Storm\" using their years attribute, then taking at join dataset and connecting it to \"global_temps\" using the month and year attributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21d9e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changeing the attribute names to match where the are being joined\n",
    "dataset_2 = dataset_2.rename(columns={\"YEAR\": \"Year\"})\n",
    "\n",
    "#modifiy dataset_3 so it is more aligned with the format of the other data types for merging\n",
    "dataset_3 = pd.melt(dataset_3,\n",
    "                    id_vars=  [\"Year\"],\n",
    "                    value_vars=  [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"],\n",
    "                    var_name=  \"MONTH\", #matching dataset_2\n",
    "                    value_name=  \"Temp\")\n",
    "\n",
    "#dataset_2 has the months in numbers and dataset_3 has them in string, so I mapped the values\n",
    "mapping = {\"Jan\":1, \"Feb\":2, \"Mar\":3, \"Apr\":4, \"May\":5, \"Jun\":6, \"Jul\":7, \"Aug\":8, \"Sep\":9, \"Oct\":10, \"Nov\":11, \"Dec\":12}\n",
    "dataset_3[\"MONTH\"] = dataset_3[\"MONTH\"].map(mapping)\n",
    "\n",
    "dataset_4 = pd.merge(dataset_1, dataset_2, on= \"Year\", how= \"left\") #left for keeping all data from both csv for now\n",
    "\n",
    "#print(dataset_4.head(5))\n",
    "\n",
    "final_dataset = pd.merge(dataset_4, dataset_3, on= [\"Year\", \"MONTH\"], how= \"inner\") #inner for keeping only matching data from all csv\n",
    "\n",
    "#creating and writing to a new csv\n",
    "final_dataset.to_csv(\"completed_dataset_for_IS_project_25.csv\", index= False)\n",
    "\n",
    "#Loading the new csv\n",
    "final_dataset_values = pd.read_csv(\"completed_dataset_for_IS_project_25.csv\")\n",
    "\n",
    "#Printing the first 5 rows of the final dataset csv\n",
    "print(\"From the Final Dataset: completed_dataset_for_IS_project_25\")\n",
    "print(final_dataset_values.head(5))\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
